# Reinforcement Framework
The AI will do some actions in the environment and gets rewards in an unsupervised way.
## Process 
* Agent receives the state $S_0$ from the environment
* The agent takes the action $A_0$
* The environment moves to the new state $S_1$
* The environment gives the reward $R_1$
* It is also called as Markov Decision Process
The loop follows :
1. State
2. Action 
3. Reward
4. Next state
The goal of the agent is to maximize the reward.
## Markov property
Property implies that agent needs only the current state and not the history of states and actions that took before by the agent.

## Space
Observation/States space are the information that environment gives to the agent.

| Observation | State |
|---|---|
| Partial information | Complete information |
* Observation - partial information about the environment is given to the agent
* State - complete information about the environment is given to the agent
### Action Space
It tells the list of all actions that can be taken by the agent
* Discrete space - Actions are finite
* Continuous space -  Actions are infinite

## Rewards and Discount
* Rewards tells the agent whether the action taken in a state was good or not.
* `Cumulative Reward` is the sum of all rewards got by the agent.
* Discount is denoted as `gamma`. To get long term reward as a goal then the gamma is bigger and vice versa.

---
# Type of task
A task is the **instance** of the RL problem. The types are :
* Episode
* Continual

| Episodic Task | Continuing Task |
| --- | --- |
| Has starting and ending point | Has no terminal state |
| Eg: Super Mario | Eg: Stock Market |

---
# Exploration and Exploitation Tradeoff
* Exploration - exploring environment to gain more information about the environment
* Exploitation - exploiting known information to gain more reward
* EE Tradeoff balances how much we want to **explore** the environment and how much we want to **exploit** what we know about the environment.
* Goal of our RL model is to maximize the cumulative reward
---
# Approach for solving environment
There are two policy :
1. Policy **π**
	1. Brain of our agent
	2. It is a function that tells the action
	3. It defines the agent behavior at a given time
	4. In RL , the policy is the term that needs to be trained
Goal is to find the optimal policy **π**
2. Approaches
	 * Policy based method
		 * Teaching the agent to learn which **action** to take
	 * Value based method
		 * Teaching the agent to learn which state is valuable and make the agent to take an action to reach the valuable state.
		 * There are two types:
			 * State value function
			 * Action value function

## Policy based 
* The agent learns directly without needing a value function.
* It takes random action at each state.
* Iteratively it learns which action leads positive reward and it finally gains optimal policy
### Types
1. Deterministic
	1. Only one action in a given state.
	2. The deterministic policy gives only the particular action for the given state
	3. Examples:
		1. DDPG - Deep Deterministic Policy Gradient 
		2. DPG - Deterministic Policy Gradient
2. Stochastic
	1. The agent chooses action by probability distribution
	2. There are multiple actions available for the agent but it chooses only high probability
	3. Examples:
		1. Soft Actor Critic
		2. Proximal Policy Optimization (PPO)

## Value based
* The goal is to optimize the value function
* The value function tells the reward for each state of the environment
* The Bellman Equation
	* Provides value to the current state and successor state
* Examples
	* SARSA
	* Q-Learning
* Task that can be solved by this approach:
	* Energy Storage Optimization
	* Robot control
	* Games like GO (Alpha Go),checkers
	* Autonomous driving system
	* Continuous state and action space

### Type
* State value function
* Action value function
# Resource
* [RL Book](http://incompleteideas.net/book/RLbook2020.pdf)
* [Check My Progress Deep RL Course - a Hugging Face Space by ThomasSimonini](https://huggingface.co/spaces/ThomasSimonini/Check-my-progress-Deep-RL-Course)
* [Deep Reinforcement Learning Leaderboard - a Hugging Face Space by huggingface-projects](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)